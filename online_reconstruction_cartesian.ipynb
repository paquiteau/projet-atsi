{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Based on \"online_gpu\" branch\n",
    "Neuroimaging cartesian reconstruction\n",
    "=====================================\n",
    "\n",
    "Credit: A Grigis, L Elgueddari, H Carrie\n",
    "\n",
    "In this tutorial we will reconstruct an MRI image from the sparse kspace\n",
    "measurments.\n",
    "\n",
    "Import neuroimaging data\n",
    "------------------------\n",
    "\n",
    "We use the toy datasets available in pysap, more specifically a 2D brain slice\n",
    "and the acquistion cartesian scheme.\n",
    "We also add some gaussian noise in the image space.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package import\n",
    "import pysap\n",
    "from parallel_mri.proximity import Threshold\n",
    "from parallel_mri_online.utils import compute_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party import\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.fftpack as pfft\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage.morphology import binary_closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modopt.opt.linear import Identity\n",
    "from modopt.opt.algorithms import Condat\n",
    "from modopt.math.metrics import ssim\n",
    "from twixreader import Twix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mri.operators.utils import convert_mask_to_locations\n",
    "from mri.operators.fourier.cartesian import FFT\n",
    "from mri.operators import OWL\n",
    "from parallel_mri_online.gradient import Grad2D_pMRI\n",
    "from parallel_mri_online.linear import Pywavelet2\n",
    "# Loading input data\n",
    "folder = '/home/pac/gits/phd/online_2D/single_channel_cartesian/2017-04-04_sparkling2D_paper/'\n",
    "data_path = folder + 'meas_MID276_CSGRE_ref_OS1_FID10929.dat'\n",
    "twix = Twix(data_path)\n",
    "kspace_ref = np.squeeze(twix[0]['ima'].raw()).reshape((32, 512, 512))\n",
    "NEX = 20\n",
    "kspace_ref = np.mean(kspace_ref[:NEX, :, :], axis=0)\n",
    "I = pfft.ifftshift(pfft.ifft2(pfft.fftshift(kspace_ref))).astype(\"complex128\")\n",
    "idx_seq = np.load(folder + 'cartesian_idx_sequence_1.npy')\n",
    "mask = np.load(folder + \"cartesian_line_UF_2.npy\")\n",
    "im_mask = np.zeros(I.shape)\n",
    "im_mask[np.abs(I) > 3e-08] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargestCC(segmentation):\n",
    "    labels = label(segmentation, background=0)\n",
    "    bincounts = np.bincount(labels.flat)\n",
    "    idx = np.argsort(bincounts)[::-1]\n",
    "    largestCC = np.copy(labels == idx[1])\n",
    "    return largestCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_mask = binary_closing(getLargestCC(im_mask), np.ones((5, 5)))\n",
    "b_size = 88\n",
    "t_it = 0.100\n",
    "TR = 0.550\n",
    "batches = np.arange(b_size, 176 + b_size, b_size)  # [176]\n",
    "if batches.shape[0] > 1:\n",
    "    nb_it_batches = [np.floor(b_size * 1.0 * TR / t_it).astype('int') for _ in\n",
    "                     range(batches.shape[0] - 1)]\n",
    "    nb_it_batches.append(200)\n",
    "else:\n",
    "    nb_it_batches = [200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = folder + 'online_reconstrcution_batch_size_' + str(b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dir_exist = False\n",
    "try:\n",
    "    os.stat(directory)\n",
    "    dir_exist = True\n",
    "except:\n",
    "    dir_exist = False\n",
    "    os.mkdir(directory)\n",
    "    os.mkdir(directory + '/masks_batches/')\n",
    "    os.mkdir(directory + '/images_batches/')\n",
    "    os.mkdir(directory + '/times_batches/')\n",
    "if dir_exist:\n",
    "    try:\n",
    "        os.stat(directory + '/masks_batches/')\n",
    "    except:\n",
    "        os.mkdir(directory + '/masks_batches/')\n",
    "    try:\n",
    "        os.stat(directory + '/images_batches/')\n",
    "    except:\n",
    "        os.mkdir(directory + '/images_batches/')\n",
    "    try:\n",
    "        os.stat(directory + '/times_batches/')\n",
    "    except:\n",
    "        os.mkdir(directory + '/times_batches/')\n",
    "#############################################################################\n",
    "# Generate the kspace\n",
    "# -------------------\n",
    "#\n",
    "# From the 2D brain slice and the acquistion mask, we generate the acquisition\n",
    "# measurments, the observed kspace.\n",
    "# We then reconstruct the zero order solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the subsampled kspace\n",
    "kspace = mask * pfft.ifftshift(pfft.fft2(pfft.fftshift(I)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the locations of the kspace samples\n",
    "kspace_loc = convert_mask_to_locations(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_op = Pywavelet2(\"sym8\", nb_scale=4, multichannel=True)\n",
    "coeffs = linear_op.op(np.expand_dims(I, axis=0))\n",
    "mu = 1e-8 / 176\n",
    "prox_dual_op = Threshold(weights=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_op = FFT(sample=kspace_loc, shape=I.shape)\n",
    "gradient_op = Grad2D_pMRI(data=np.expand_dims(np.zeros_like(kspace), axis=0),\n",
    "                          fourier_op=fourier_op,\n",
    "                          gradient_spec_rad=1.1)\n",
    "gradient_op.fourier_op._mask = np.zeros_like(mask)\n",
    "# Start the POGM reconstruction\n",
    "# max_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_op = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "sigma = 0.5\n",
    "eps = 5e-8\n",
    "norm = 1.0  # linear_op.l2norm(np.expand_dims(I, axis=0).shape)\n",
    "tau = 1.0 / (gradient_op.spec_rad / 2 + sigma * norm ** 2 + eps)\n",
    "opt = Condat(\n",
    "    x=np.zeros((1, *fourier_op.shape), dtype=\"complex128\"),\n",
    "    y=np.zeros_like(coeffs),\n",
    "    grad=gradient_op,\n",
    "    prox=prox_op,\n",
    "    prox_dual=prox_dual_op,\n",
    "    linear=linear_op,\n",
    "    cost=None,\n",
    "    rho=1.0,\n",
    "    sigma=sigma,\n",
    "    tau=tau,\n",
    "    rho_update=None,\n",
    "    sigma_update=None,\n",
    "    tau_update=None,\n",
    "    auto_iterate=False)\n",
    "final_ssim = []\n",
    "time_batches = []\n",
    "time_batches.append(batches[0] * TR)\n",
    "final_ssim.append(0)\n",
    "final_ssim = np.asarray(final_ssim)\n",
    "final_cost = []\n",
    "final_cost.append(np.sum(np.abs(opt._grad.op(np.zeros_like(opt._x_old)) -\n",
    "                                kspace_ref) ** 2) +\n",
    "                  opt._prox_dual.weights * np.sum(\n",
    "    np.abs(opt._linear.op(np.zeros_like(opt._x_old)))))\n",
    "final_cost = np.asarray(final_cost)\n",
    "time_batches = np.asarray(time_batches)\n",
    "fig, ax = plt.subplots()\n",
    "for idx, batch in enumerate(batches):\n",
    "    obs_data = np.copy(opt._grad.obs_data)\n",
    "    obs_data[:, :, idx_seq[:batch]] = kspace_ref[:, idx_seq[:batch]]\n",
    "    opt._grad = Grad2D_pMRI(data=obs_data,\n",
    "                            fourier_op=fourier_op,\n",
    "                            gradient_spec_rad=1.1)\n",
    "    opt._grad.fourier_op._mask[:, idx_seq[:batch]] = np.ones((I.shape[0], batch))\n",
    "    cost_func_batch = []\n",
    "    ssim_batches = []\n",
    "    print(batch, opt._prox_dual.weights)\n",
    "    opt._prox_dual.weights = mu * batch\n",
    "    time_it = []\n",
    "    # cost_func_batch.append()\n",
    "    for _ in range(nb_it_batches[idx]):\n",
    "        start = time.time()\n",
    "        opt._update()\n",
    "        stop = time.time()\n",
    "        time_it.append(stop - start)\n",
    "        cost_func_batch.append(np.sum(np.abs(opt._grad.op(opt._x_new) -\n",
    "                                             kspace_ref) ** 2) +\n",
    "                               opt._prox_dual.weights * np.sum(np.abs(opt._y_new)))\n",
    "        ssim_batches.append(compute_ssim(np.fft.fftshift(np.squeeze(opt._x_new)), I))\n",
    "    np.save(directory + '/times_batches/time_batch_nb_' + str(idx), time_it)\n",
    "    #  Saving batch mask\n",
    "    ax.imshow(opt._grad.fourier_op._mask, cmap='gray');\n",
    "    ax.axis('off')\n",
    "    imsave_path = directory + '/masks_batches/mask_batch_{0:03d}.png'.format(batch)\n",
    "    plt.imsave(fname=imsave_path, arr=opt._grad.fourier_op._mask)\n",
    "    #  Saving images\n",
    "    np.save(directory + '/images_batches/image_batch_nb_{0:03d}'.format(idx), opt._x_new)\n",
    "    ax.imshow(np.fft.fftshift(np.squeeze(np.abs(opt._x_new))), cmap='gray');\n",
    "    ax.axis('off')\n",
    "    imsave_path = directory + '/images_batches/I_batch_{0:03d}.png'.format(batch)\n",
    "    plt.imsave(fname=imsave_path, arr=np.fft.fftshift(np.squeeze(np.abs(opt._x_new))), cmap='gray')\n",
    "    # Updating cost function\n",
    "    time_batches = np.concatenate((time_batches, np.asarray(time_it)))\n",
    "    final_cost = np.concatenate((final_cost, np.asarray(cost_func_batch)))\n",
    "    final_ssim = np.concatenate((final_ssim, np.asarray(ssim_batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(directory + '/resume_time.npy', np.asarray(time_batches))\n",
    "np.save(directory + '/resume_cost.npy', final_cost)\n",
    "np.save(directory + '/resume_ssim.npy', final_ssim)\n",
    "plt.figure()\n",
    "plt.plot(final_cost)\n",
    "plt.figure()\n",
    "plt.plot(final_ssim)\n",
    "plt.figure()\n",
    "plt.imshow(np.fft.fftshift(np.squeeze(np.abs(opt._x_old))))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
